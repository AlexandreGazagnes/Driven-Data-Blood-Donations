{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nin this second part, we will implement our first logistic regression model.\\nWe will first implement by hand a naive classifier, then a dummy classifier \\n(who does the same job), and finally a basic logistic regression model.\\nrather than looking at the results of a regression we will implement a \\nfunction that will test the model x times and that will average the results\\n obtained\\nwe will then implement a results manager that will be a dataframe\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "#-*- coding: utf8 -*-\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "01-first-naive-model.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "in this second part, we will implement our first logistic regression model.\n",
    "We will first implement by hand a naive classifier, then a dummy classifier \n",
    "(who does the same job), and finally a basic logistic regression model.\n",
    "rather than looking at the results of a regression we will implement a \n",
    "function that will test the model x times and that will average the results\n",
    " obtained\n",
    "we will then implement a results manager that will be a dataframe\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.grid_search import *\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_don</th>\n",
       "      <th>num_don</th>\n",
       "      <th>first_don</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     last_don  num_don  first_don  target\n",
       "619         2       50         98       1\n",
       "664         0       13         28       1\n",
       "441         1       16         35       1\n",
       "160         2       20         45       1\n",
       "358         1       24         77       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pasting first_tour.ipynb if nedeed\n",
    "\n",
    "\n",
    "###############################################################\n",
    "###############################################################\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# please see first_tour.ipynb before\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "###############################################################\n",
    "###############################################################\n",
    "\n",
    "\n",
    "# import\n",
    "import os, sys, logging, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# logging \n",
    "l = logging.WARNING\n",
    "logging.basicConfig(level=l, format=\"%(levelname)s : %(message)s\")\n",
    "info = logging.info\n",
    "\n",
    "# graph\n",
    "# %matplotlib\n",
    "# sns.set()\n",
    "\n",
    "# consts\n",
    "FOLDER      = \"Driven-Data-Blood-Donations\"\n",
    "TRAIN_FILE  = \"training_data.csv\"\n",
    "TEST_FILE   = \"test_data.csv\"\n",
    "\n",
    "# functions\n",
    "\n",
    "def finding_master_path(folder=\"data\") :\n",
    "    path = os.getcwd()\n",
    "    path = path.split(\"/\")\n",
    "    idx  = path.index(FOLDER)\n",
    "    path = path[:idx+1]\n",
    "    folder = str(folder) + \"/\"\n",
    "    path.append(folder)  \n",
    "    path = \"/\".join(path)\n",
    "    if not os.path.isdir(path) : \n",
    "        raise NotADirectoryError\n",
    "    return path\n",
    "    \n",
    "def return_datasets(path) : \n",
    "    li = [i for i in os.listdir(path) if \".csv\" in i ]\n",
    "    return li \n",
    "\n",
    "def build_df(path, file) : \n",
    "    df          = pd.read_csv(path+file, index_col=0)\n",
    "    df.columns  = pd.Index( [\"last_don\", \"num_don\",\"vol_don\", \"first_don\", \n",
    "                            \"target\"], dtype=\"object\")\n",
    "    return df\n",
    "\n",
    "def print_df(df) : \n",
    "    print(df.ndim)\n",
    "    print(df.shape)\n",
    "    print(df.dtypes)\n",
    "    print(df.index)\n",
    "    print(df.columns)\n",
    "    print(df.describe())\n",
    "    print(df.head(3))\n",
    "    print(df.tail(3))\n",
    "\n",
    "def re_dtype(df) : \n",
    "    # li = [np.uint8, np.uint16]\n",
    "    # [print(i,  np.iinfo(i).min, np.iinfo(i).max) for i in li]\n",
    "    dtypes_dict = {     \"last_don\"  : np.uint8, \n",
    "                        \"num_don\"   : np.uint8,\n",
    "                        \"vol_don\"   : np.uint16, \n",
    "                        \"first_don\" : np.uint8, \n",
    "                        \"target\"    : np.uint8       }\n",
    "    df = df.astype(dtypes_dict)\n",
    "    return df \n",
    "\n",
    "def graph_each_feature(df)  : \n",
    "    features = [i for i in df.columns if \"target\" not in i] \n",
    "    fig, _axes = plt.subplots(2, 2, figsize=(13,13))\n",
    "    axes = _axes.flatten()\n",
    "    info(fig)\n",
    "    info(axes)\n",
    "    info(len(axes))\n",
    "    for i, feat in enumerate(features) :\n",
    "        info(i, feat)\n",
    "        # -----------------------------------------\n",
    "        # sns.distplot --> (kde=True ) ???\n",
    "        # -----------------------------------------\n",
    "        axes[i].hist(df[feat], bins=30)\n",
    "        axes[i].set_title(feat)\n",
    "    plt.suptitle(\"features distribution\")\n",
    "    plt.show()\n",
    "\n",
    "def graph_corr_matrix(df) : \n",
    "    corr_mat = df.corr()\n",
    "    sns.heatmap(corr_mat, cmap=\"coolwarm\", annot=True, fmt='.3g')\n",
    "    plt.title(\"correlation matrix\")\n",
    "    plt.show()\n",
    "\n",
    "def drop_corr_features(df) : \n",
    "    df = df.drop(\"vol_don\", axis=1)\n",
    "    return df \n",
    "\n",
    "def study_nas(df) : \n",
    "    print(df.isna().any())\n",
    "    print(df.isna().any())\n",
    "\n",
    "def study_outliers(df, k=1.5) : \n",
    "    fig, _axes = plt.subplots(1, 5, figsize=(13,13))\n",
    "    axes = _axes.flatten()\n",
    "    info(fig)\n",
    "    info(axes)\n",
    "    info(len(axes))\n",
    "    for i, feat in enumerate(df.columns) :\n",
    "        info(i, feat)\n",
    "        axes[i].boxplot(df[feat], whis=k)\n",
    "        axes[i].set_title(feat)\n",
    "    plt.suptitle(\"features outliers, k of {}\".format(whis))\n",
    "    plt.show()\n",
    "\n",
    "def return_outliers(ser, k) : \n",
    "    desc = ser.describe()\n",
    "    q1, q3, q2 = desc[\"25%\"], desc[\"75%\"], desc[\"50%\"]\n",
    "    IQ = q3-q1\n",
    "    range_min, range_max = q1 - k * IQ, q3 + k*IQ\n",
    "    # outliers = ser[(ser > range_max) or (ser < range_min)] \n",
    "    return ser >= range_max\n",
    "\n",
    "def delete_outliers(df, k) : \n",
    "    li = [i for i in df.columns if \"target\" not in i]\n",
    "    for feat in li : \n",
    "        df = df[return_outliers(df[feat], k) == False]\n",
    "    return df\n",
    "\n",
    "def first_tour(folder=\"data\", file=TRAIN_FILE) : \n",
    "    # build data path\n",
    "    path = finding_master_path(\"data\")\n",
    "    # info(path)\t\t\t\t\t\t\t# UNCOMMENT IF NEEDED\n",
    "    # just show dataset list\n",
    "    # datasets = return_datasets(path)      # UNCOMMENT IF NEEDED\n",
    "    # info(datasets)                        # UNCOMMENT IF NEEDED\n",
    "    # build our df\n",
    "    df = build_df(path, file)\n",
    "    # print main info\n",
    "    # print_df(df)                          # UNCOMMENT IF NEEDED\n",
    "    # (overkilled) recast dataframe in a better dtype\n",
    "    df = re_dtype(df)\n",
    "    # graph features distr and correlation  # UNCOMMENT IF NEEDED\n",
    "    # graph_each_feature(df)                  \n",
    "    # graph_corr_matrix(df)                 # UNCOMMENT IF NEEDED\n",
    "    # drop corr values\n",
    "    df = drop_corr_features(df)\n",
    "    # nas\n",
    "    # study_nas(df)                         # UNCOMMENT IF NEEDED\n",
    "    # for i in [1.5, 2, 2.5, 3] :           # UNCOMMENT IF NEEDED\n",
    "    # study_outliers(df, i)                 # UNCOMMENT IF NEEDED\n",
    "    # df = delete_outliers(df, 3)           # UNCOMMENT IF NEEDED\n",
    "    return df\n",
    "\n",
    "####\n",
    "\n",
    "df = first_tour()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts \n",
    "\n",
    "COLUMNS = [\"naive\", \"dummy\", \"basic\", \"features eng.\"]\n",
    "# MODELS = [naive_model, dummy_model, basic_model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our features from our target\n",
    "\n",
    "def return_X_y(df) : \n",
    "    \n",
    "    X = df.drop(\"target\", axis=1)\n",
    "    y = df.target\n",
    "\n",
    "    return X, y  \n",
    "\n",
    "####\n",
    "\n",
    "X,y = return_X_y(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test and train df/target\n",
    "\n",
    "def split(X,y) : \n",
    "\n",
    "    func = train_test_split\n",
    "    tup = train_test_split(X, y)\n",
    "\n",
    "    return tup\n",
    "\n",
    "####\n",
    "\n",
    "tup = split(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.646"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build from scratch a naive/dummy model which make prediction regarding global target probabilities\n",
    "\n",
    "def naive_model(df=None) : \n",
    "\n",
    "    if not isinstance(df, pd.DataFrame): \n",
    "        df = first_tour()\n",
    "\n",
    "    X,y = return_X_y(df)\n",
    "    t = split(X,y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = t \n",
    "\n",
    "    freq = y_test.value_counts() / len(y_test)\n",
    "\n",
    "    y_pred = np.random.binomial(1, freq[1], len(y_test))\n",
    "    y_pred = pd.Series(y_pred)\n",
    "\n",
    "    return accuracy_score(y_test, y_pred).round(3)\n",
    "\n",
    "####\n",
    "\n",
    "naive_model(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.611"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rather than conding a dummy model from scratch, use sk learn DummyClassifier (same job) \n",
    "\n",
    "def dummy_model(df=None) : \n",
    "\n",
    "    if not isinstance(df, pd.DataFrame): \n",
    "        df = first_tour()\n",
    "\n",
    "    X,y = return_X_y(df)\n",
    "    t = split(X,y)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = t \n",
    "\n",
    "    model = DummyClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return accuracy_score(y_test, y_pred).round(3)\n",
    "\n",
    "####\n",
    "\n",
    "dummy_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just for fun trying to make predictions with a very basic model (no meta params, no features engineering)\n",
    "# this one will be our model prediction base\n",
    "# it is suposed to be better that our DummyClassifier. If not there is a major issue...\n",
    "\n",
    "def basic_model(df=None) : \n",
    "\n",
    "    if not isinstance(df, pd.DataFrame): \n",
    "        df = first_tour()\n",
    "\n",
    "    X,y = return_X_y(df)\n",
    "    t = split(X,y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = t \n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return accuracy_score(y_test, y_pred).round(3)\n",
    "\n",
    "####\n",
    "\n",
    "basic_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.645\n",
      "0.604\n",
      "0.747\n"
     ]
    }
   ],
   "source": [
    "# we now need to have a sort of decorator which will be charged to lunch n times our model and to give \n",
    "# us the accuracy mean of n trials\n",
    "\n",
    "def model_accuracy_mean(model, nb=5, df=None) : \n",
    "\n",
    "    scores = [model(df) for i in range(nb)]\n",
    "\n",
    "    info(type(scores))\n",
    "    info(type(range(nb)))\n",
    "\n",
    "    score = sum(scores)/len(scores)\n",
    "\n",
    "    return score.round(3)\n",
    "\n",
    "####\n",
    "\n",
    "print(model_accuracy_mean(naive_model))\n",
    "print(model_accuracy_mean(dummy_model))\n",
    "print(model_accuracy_mean(basic_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive</th>\n",
       "      <th>dummy</th>\n",
       "      <th>basic</th>\n",
       "      <th>feat eng.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [naive, dummy, basic, feat eng.]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we now will be able to build a specific dataframe to handle results of various tested models\n",
    "\n",
    "COLUMNS = [\"naive\", \"dummy\", \"basic\", \"feat eng.\"]\n",
    "MODELS =  [naive_model, dummy_model, basic_model]\n",
    "\n",
    "results = pd.DataFrame(columns=COLUMNS)\n",
    "\n",
    "####\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive</th>\n",
       "      <th>dummy</th>\n",
       "      <th>basic</th>\n",
       "      <th>feat eng.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.749</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   naive  dummy  basic feat eng.\n",
       "0   0.67  0.603  0.749      test"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and for each feature engineering configuration, we will have a function charged to run every \n",
    "# listed models and to add properly the results in our specific dataframe\n",
    "\n",
    "def add_new_results(feat_com=None,\n",
    "                    results=None, \n",
    "                    n=5, \n",
    "                    models=MODELS, \n",
    "                    columns= COLUMNS,\n",
    "                    df=None) : \n",
    "\n",
    "    if not isinstance(results, pd.DataFrame) : \n",
    "        results = pd.DataFrame(columns=columns)\n",
    "\n",
    "    new = [model_accuracy_mean(i, n, df) for i in models]\n",
    "\n",
    "    info(new)\n",
    "\n",
    "    if not feat_com : \n",
    "        feat_com = \"No comment\"\n",
    "\n",
    "    new.append(feat_com)\n",
    "    info(new)\n",
    "    \n",
    "    new = pd.Series(new, index=columns)\n",
    "    info(new)\n",
    "\n",
    "    results = results.append(new, ignore_index=True)\n",
    "    info(results)\n",
    "\n",
    "    return results\n",
    "\n",
    "####\n",
    "\n",
    "results = add_new_results(\"test\")\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive</th>\n",
       "      <th>dummy</th>\n",
       "      <th>basic</th>\n",
       "      <th>feat eng.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.638</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.784</td>\n",
       "      <td>drop outliers with threshold of k &gt; 1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.781</td>\n",
       "      <td>drop outliers with threshold of k &gt; 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.668</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.783</td>\n",
       "      <td>drop outliers with threshold of k &gt; 2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.618</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.793</td>\n",
       "      <td>drop outliers with threshold of k &gt; 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   naive  dummy  basic                                feat eng.\n",
       "0  0.638  0.630  0.784  drop outliers with threshold of k > 1.5\n",
       "1  0.666  0.648  0.781    drop outliers with threshold of k > 2\n",
       "2  0.668  0.637  0.783  drop outliers with threshold of k > 2.5\n",
       "3  0.618  0.643  0.793    drop outliers with threshold of k > 3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally just to test this \"meta\" model we will test it with our first featue engineering \n",
    "# possibility : outilers threshold\n",
    "# we do not care so much about the results but about the global process of our meta model\n",
    "# of course if we can find a first way for our feature engineering work, it could be great! \n",
    "\n",
    "def first_approch_of_feat_eng(  drop_list,\n",
    "                                results=None,\n",
    "                                n=5, models=MODELS, columns=COLUMNS, df=None) : \n",
    "\n",
    "    if not isinstance(drop_list, list) : \n",
    "        raise TypeError\n",
    "\n",
    "    if not isinstance(results, pd.DataFrame) : \n",
    "        results = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for i in drop_list : \n",
    "\n",
    "        df = first_tour()\n",
    "        df = delete_outliers(df, i) \n",
    "\n",
    "        feat_com = \"drop outliers with threshold of k > \" + str(i)\n",
    "\n",
    "        results = add_new_results(  results=results,\n",
    "                                    feat_com=feat_com,\n",
    "                                    n=n, \n",
    "                                    models=models, \n",
    "                                    columns=columns, \n",
    "                                    df=df)\n",
    "\n",
    "    return results\n",
    "\n",
    "####\n",
    "\n",
    "results = first_approch_of_feat_eng([1.5, 2, 2.5, 3])\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive</th>\n",
       "      <th>dummy</th>\n",
       "      <th>basic</th>\n",
       "      <th>feat eng.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.608</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.775</td>\n",
       "      <td>without_any_feat_eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.778</td>\n",
       "      <td>drop outliers with threshold of k &gt; 1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.617</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.760</td>\n",
       "      <td>drop outliers with threshold of k &gt; 2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.611</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.777</td>\n",
       "      <td>drop outliers with threshold of k &gt; 2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.641</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.772</td>\n",
       "      <td>drop outliers with threshold of k &gt; 3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.646</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.771</td>\n",
       "      <td>drop outliers with threshold of k &gt; 3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   naive  dummy  basic                                feat eng.\n",
       "0  0.608  0.636  0.775                     without_any_feat_eng\n",
       "1  0.643  0.653  0.778  drop outliers with threshold of k > 1.5\n",
       "2  0.617  0.643  0.760  drop outliers with threshold of k > 2.0\n",
       "3  0.611  0.631  0.777  drop outliers with threshold of k > 2.5\n",
       "4  0.641  0.635  0.772  drop outliers with threshold of k > 3.0\n",
       "5  0.646  0.642  0.771  drop outliers with threshold of k > 3.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just for ther record, let's build a function which resume all this work in 3 ligns\n",
    "\n",
    "def first_naive_model() : \n",
    "\n",
    "    results = pd.DataFrame(columns=COLUMNS)\n",
    "    results = add_new_results(\"without_any_feat_eng\", results)\n",
    "\n",
    "    results = first_approch_of_feat_eng([1.5, 2.0, 2.5, 3.0, 3.5], results)\n",
    "\n",
    "    return results\n",
    "\n",
    "####\n",
    "\n",
    "first_naive_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conclusion\n",
    "\n",
    "# We could see through this first study that we are on a dataset quite simple, allowing our first approach \n",
    "# to have pretty good results.\n",
    "\n",
    "# Our base model offers a performance of 0.75 and the impact of the ouliers on the model's performance \n",
    "# seems at first glance quite low.\n",
    "\n",
    "# Having a fairly simple dataset, the possibilities for improving the models will not be that simple due \n",
    "# to the small number of variables and the small size of the dataset : the possibilities offered by \n",
    "# the feature engineering are indeed quite low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
